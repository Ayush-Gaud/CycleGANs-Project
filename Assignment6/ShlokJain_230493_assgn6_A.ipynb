{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0bHEuoAPX47"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import ImageFolder, MNIST\n",
        "from torchvision import transforms\n",
        "from torch import autograd\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import make_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8InLg95PYzH"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([    #pytorch image transform pipeline\n",
        "        transforms.ToTensor(),                #convert to tensor\n",
        "        transforms.Normalize([0.5], [0.5])    # value = (value-0.5)/0.5 normalization, convert range from [0,1] to [-1,1]\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtK7jTV9PcPK"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "# loader for mnist\n",
        "data_loader = torch.utils.data.DataLoader(MNIST('data', train=True, download=True, transform=transform),batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lxs17ihuPeNZ"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module): #inherited from nn.Module\n",
        "    def __init__(self):\n",
        "        super().__init__()      #init of nn.Module\n",
        "\n",
        "        self.label_emb = nn.Embedding(10, 10)  # embedding label, assigns a 10 length vector to each label\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(794, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        x = x.view(x.size(0), 784) #resize image to flatten it\n",
        "        c = self.label_emb(labels) #embedding labels\n",
        "        x = torch.cat([x, c], 1)   #concat x and c\n",
        "        out = self.model(x)\n",
        "        return out.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QdQVQo1PgB6"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.label_emb = nn.Embedding(10, 10)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(110, 256),                #110 = 100+10 input neurons and passes 256 output neurons ahead\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, 784),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        z = z.view(z.size(0), 100)\n",
        "        c = self.label_emb(labels) #embedding labels\n",
        "        x = torch.cat([z, c], 1)   #concat z and c\n",
        "        out = self.model(x)\n",
        "        return out.view(x.size(0), 28, 28) #reshape output to image size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpHaU2JEPh2u"
      },
      "outputs": [],
      "source": [
        "generator = Generator().cuda()\n",
        "discriminator = Discriminator().cuda()\n",
        "criterion = nn.BCELoss() #binary cross entropy loss\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-4)\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmChHgpGPwBm"
      },
      "outputs": [],
      "source": [
        "def generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion):\n",
        "    g_optimizer.zero_grad() #zeroes out previous accumulated gradients\n",
        "    z = Variable(torch.randn(batch_size, 100)).cuda()  #generate random noise of 100 length\n",
        "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, 10, batch_size))).cuda() #generate random labels\n",
        "    fake_images = generator(z, fake_labels) #generate fake images\n",
        "    validity = discriminator(fake_images, fake_labels) #pass to discriminator to classify real or fake\n",
        "    g_loss = criterion(validity, Variable(torch.ones(batch_size)).cuda()) #calculate loss, with vector of ones because we generator wants disc. to classify all as real\n",
        "    g_loss.backward() #backprop\n",
        "    g_optimizer.step() #update weights and biases\n",
        "    return g_loss.item() #return loss value\n",
        "\n",
        "def discriminator_train_step(batch_size, discriminator, generator, d_optimizer, criterion, real_images, labels):\n",
        "    d_optimizer.zero_grad() #zeroes out previous accumulated gradients\n",
        "\n",
        "    # train with real images\n",
        "    real_validity = discriminator(real_images, labels)\n",
        "    real_loss = criterion(real_validity, Variable(torch.ones(batch_size)).cuda()) #calc loss with vector of ones, as all are real\n",
        "\n",
        "    # train with fake images\n",
        "    z = Variable(torch.randn(batch_size, 100)).cuda() #generate random noise of 100 length\n",
        "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, 10, batch_size))).cuda() #generate random labels\n",
        "    fake_images = generator(z, fake_labels) #generate fake images\n",
        "    fake_validity = discriminator(fake_images, fake_labels) #pass to discriminator to classify real or fake\n",
        "    fake_loss = criterion(fake_validity, Variable(torch.zeros(batch_size)).cuda()) #calc loss with vector of zeros, as all are fake\n",
        "\n",
        "    d_loss = real_loss + fake_loss #combine losses\n",
        "    d_loss.backward() #backprop\n",
        "    d_optimizer.step() #update weights and biases\n",
        "    return d_loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WAYjW6NoP5L8"
      },
      "outputs": [],
      "source": [
        "num_epochs = 50\n",
        "n_critic = 5 # number of times discrimimnator is trained per one generator training step\n",
        "display_step = 50\n",
        "for epoch in range(num_epochs):\n",
        "    print('Starting epoch {}...'.format(epoch), end=' ')\n",
        "    for i, (images, labels) in enumerate(data_loader):\n",
        "\n",
        "        step = epoch * len(data_loader) + i + 1\n",
        "        real_images = Variable(images).cuda()\n",
        "        labels = Variable(labels).cuda()\n",
        "        generator.train()       #tells the model that it is in training phase\n",
        "\n",
        "        d_loss = 0\n",
        "        for _ in range(n_critic):\n",
        "            d_loss = discriminator_train_step(len(real_images), discriminator,generator, d_optimizer, criterion, real_images, labels)\n",
        "\n",
        "\n",
        "        g_loss = generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion)\n",
        "\n",
        "\n",
        "        if step % display_step == 0:\n",
        "            generator.eval()\n",
        "            z = Variable(torch.randn(9, 100)).cuda()\n",
        "            labels = Variable(torch.LongTensor(np.arange(9))).cuda()\n",
        "            sample_images = generator(z, labels).unsqueeze(1)\n",
        "            grid = make_grid(sample_images, nrow=3, normalize=True)\n",
        "    print('Done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lt7kD2mtP9yg"
      },
      "outputs": [],
      "source": [
        "torch.save(generator.state_dict(), 'generator_state.pt')\n",
        "z = Variable(torch.randn(100, 100)).cuda()\n",
        "labels = torch.LongTensor([i for i in range(10) for _ in range(10)]).cuda()\n",
        "images = generator(z, labels).unsqueeze(1)\n",
        "grid = make_grid(images, nrow=10, normalize=True)\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "ax.imshow(grid.permute(1, 2, 0).data, cmap='binary')\n",
        "ax.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_digit(generator, digit):\n",
        "    z = Variable(torch.randn(1, 100)).cuda()\n",
        "    label = torch.LongTensor([digit]).cuda()\n",
        "    img = generator(z, label).data.cpu()\n",
        "    img = 0.5 * img + 0.5\n",
        "    return transforms.ToPILImage()(img)\n",
        "generate_digit(generator, 8)"
      ],
      "metadata": {
        "id": "fF42EYz-gogQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}